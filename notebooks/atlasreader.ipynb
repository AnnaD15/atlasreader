{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNI Atlas Reader\n",
    "\n",
    "A Python interface for generating coordinate tables and region labels from fMRI statistical images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.datasets import fetch_neurovault_motor_task, fetch_neurovault_auditory_computation_task\n",
    "from nilearn import plotting\n",
    "import atlasreader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Stat Map\n",
    "\n",
    "First, let's grab an example stat map. We'll use `nilearn` to grab a motor task stat map from [neurovault](https://neurovault.org/). Note that you'll need the most up to date version of `nilearn` in order to run `fetch_neurovault_motor_task()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motor_images = fetch_neurovault_motor_task()\n",
    "stat_img = motor_images.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an output folder in the directory of stat_img\n",
    "outpath = os.path.join(os.path.dirname(stat_img), 'clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plotting.plot_stat_map(stat_img, threshold=3, black_bg=True, vmax=10,\n",
    "                       title='Finger tapping task', cut_coords=[60, -19, 46])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlas Reader from the Command Line\n",
    "\n",
    "Now that we have our stat map, we can run `atlasreader` directly from the command line to extract out the peaks and cluster information. Let's begin with running the `help` argument so we can look at the input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "atlasreader -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so now we can run `atlasreader` and provide our stat map and the out directory that we made earlier. Let's threshold our _t_ values to 5 and set the `extent` to 10 in order to get robust clusters of at least 10 or more voxels. We'll also set our probability threshold to 33% to remove small probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$stat_img\" \"$outpath\"\n",
    "atlasreader $1 -a Harvard_Oxford -t 5 -c 10 -p 33 -o $2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out peak and cluster information, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in main output file\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(os.path.join(outpath, 'image_10426_peaks.csv'))\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(outpath, 'image_10426_clusters.csv'))\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also grab the cluster images that were created from our output directory. Note that the crosshair is placed on the peak voxel within the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=os.path.join(outpath, 'image_10426_cluster01.png'), width=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=os.path.join(outpath, 'image_10426_cluster02.png'), width=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling from Python\n",
    "\n",
    "You can also import the `create_output` function from the `atlasreader` module itself, and run it directly from python. Note that in this example, another atlas (`aal`) is added. We'll repeat what we ran earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlasreader.atlasreader import create_output\n",
    "\n",
    "create_output(stat_img, ['Harvard_Oxford', 'aal'],\n",
    "              voxel_thresh=3, cluster_extent=10,\n",
    "              prob_thresh=33, outdir=outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(outpath, 'image_10426_peaks.csv'))\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(outpath, 'image_10426_clusters.csv'))\n",
    "df.head(20)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

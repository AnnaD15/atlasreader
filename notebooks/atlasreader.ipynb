{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atlas Reader\n",
    "\n",
    "[Atlas Reader](https://github.com/miykael/atlasreader) is a Python interface for generating coordinate tables and region labels from statistical MRI images.\n",
    "\n",
    "## Installing `atlasreader`\n",
    "\n",
    "Provided you have `pip` at your disposal, installing `atlasreader` is as simple as this:\n",
    "\n",
    "```pip install -U atlasreader```\n",
    "\n",
    "\n",
    "## Using `atlasreader`\n",
    "\n",
    "`atlasreader` can either be run through the command line interface, or directly within Python. To showcase both of those examples, let's first import relevant plotting functions for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's download some example data via `nilearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import fetch_neurovault_motor_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a stat map from neurovault using nilearn\n",
    "motor_images = fetch_neurovault_motor_task()\n",
    "stat_img = motor_images.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what does our example data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(stat_img, black_bg=True, threshold=5,\n",
    "                          vmax=10, colorbar=True, plot_abs=False,\n",
    "                          title='Finger tapping task')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we can see that there are a few particular clusters, if we threshold the data at a value of 5.\n",
    "\n",
    "`atlasreader` gives you now the opportunity to better understand where the peaks of those clusters are, over which regions the clusters extend, and much more. So, how is it done?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling `atlasreader` from Python\n",
    "\n",
    "If you want run `atlasreader` directly in Python, just import the `create_output()` function, and you're good to go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlasreader.atlasreader import create_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's for example say that you want to get the atlas information of the statistical map from above, thresholded at a value of 5, but only for the [AAL](http://neuro.imm.dtu.dk/wiki/Automated_Anatomical_Labeling) atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_output(stat_img,\n",
    "              atlas='aal',\n",
    "              voxel_thresh=5,\n",
    "              cluster_extent=0,\n",
    "              prob_thresh=0,\n",
    "              outdir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an output we get four different kind of files.\n",
    "\n",
    "*First*, an overview glass brain plot, with the name of `stat_img` but with the file ending `.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('image_10426.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Second*, a statistical map plot for each cluster found in the data, centered around the peak of this cluster. Those files all end with `_cluster01.png`, `_cluster02.png`, ...:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('image_10426_cluster01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('image_10426_cluster02.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Third*, a csv file ending with `_peaks.csv`, containing the location of each cluster's peak, it's signal value at this location and the atlas correspondence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('image_10426_peaks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Forth*, a csv file ending with `_clusters.csv`, containing the location of each cluster's peak, it's mean value, its cluster extend, as well as the membership of each cluster, given a particular atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('image_10426_clusters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in the csv table shown above, we know that 51.68% of the first cluster is in the righ postcentral and 28.75% is in the right precentral area, according to the AAL atlas.\n",
    "\n",
    "### Adapting cluster parameters\n",
    "\n",
    "As you can see, there are some clusters with a cluster extend of less than 5000 mm³ (i.e. with a voxel resolution of 3mm x 3mm x 3mm this corresponds to about 185 voxels.\n",
    "\n",
    "So, let's say we want to ignore those clusters with less than 185 voxles / 5000 mm³ and get the atlas information for FreeSurfer's *Desikan_Killiany* and FSL's *Harvard-Oxford* atlas. To do this, we can adapt the parameters as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_output(stat_img,\n",
    "              atlas=['Desikan_Killiany', 'Harvard_Oxford'],\n",
    "              voxel_thresh=5,\n",
    "              cluster_extent=185,\n",
    "              prob_thresh=0,\n",
    "              outdir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the glass brain again, we see that only the biggest clusters have survived the restrictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('image_10426.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And looking at the two CSV tables, we can see that we now have peak and cluster information for two atlases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('image_10426_peaks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('image_10426_clusters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `atlasreader` from the Command Line\n",
    "\n",
    "This is all super exciting! But as promised before, `atlasreader` can also be run directly from the command line. Assuming you installed it via `pip`.\n",
    "\n",
    "So let's see what the options are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "atlasreader -h "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! As you can see, we have the same input parameters available as if we would run `atlasreader` within Python.\n",
    "\n",
    "So let's try something new out. Let's set the *probability threshold* to 40% and the *atlas* to `all`. The rest we can keep as in the example before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$stat_img\"\n",
    "atlasreader -a all -t 5 -c 185 -p 40 -o . $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The glassbrain will look the same, but what about the csv tables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('image_10426_peaks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we now get atlas information for all the atlases included in `atlasreader`. Currently those are AAL, FreeSurfer's Desikan-Killiany& Destrieux, FSL's Harvard-Oxford, Juelich and Neuromorphometrics atlas. This is due to the fact that we set the parameter `atlas` to `'all`.\n",
    "\n",
    "But what about the `probability threshold` parameter at 40%? This means that only atlas memberships of higher than 40% are shown in the tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('image_10426_clusters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That this is the case, becomes more eminent, if we run the same command again, but this time with the `probability threshold` parameters set to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$stat_img\"\n",
    "atlasreader -a all -t 5 -c 185 -p 0 -o . $1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('image_10426_clusters.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
